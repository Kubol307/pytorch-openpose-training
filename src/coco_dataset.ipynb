{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import VisionDataset\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(train=False):\n",
    "  if train:\n",
    "    transform = A.Compose([\n",
    "        A.Resize(640, 480, 3),\n",
    "        # A.HorizontalFlip(p=0.3),\n",
    "        # A.VerticalFlip(p=0.3),\n",
    "        # A.RandomBrightnessContrast(p=0.1),\n",
    "        # A.ColorJitter(p=0.1),\n",
    "        ToTensorV2()\n",
    "    ], bbox_params=A.BboxParams(format='coco'))\n",
    "  else:\n",
    "    transform = A.Compose([\n",
    "        A.Resize(640, 480, 3),\n",
    "        ToTensorV2()\n",
    "    ], bbox_params=A.BboxParams(format='coco'))\n",
    "  return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class COCODataset(VisionDataset):\n",
    "    def __init__(self, root, split='train', transforms=None, transform=None, target_transform=None):\n",
    "        super().__init__(root, transforms, transform, target_transform)\n",
    "        self.root = root\n",
    "        self.json = os.path.join(root, 'annotations/person_keypoints_val2017.json')\n",
    "\n",
    "        # Read annotations\n",
    "        self.coco = COCO(self.json)\n",
    "        self.split = split\n",
    "\n",
    "        # extract and sort ids\n",
    "        self.ids = sorted([img['id'] for img in self.coco.imgs.values()])\n",
    "\n",
    "        # Remove empty dicts\n",
    "        self.ids = [id for id in self.ids if len(self.coco.loadAnns(self.coco.getAnnIds(id))) > 0]\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def _load_image(self, id):\n",
    "        path = os.path.join(self.root, 'images/val2017', self.coco.imgs[id]['file_name'])\n",
    "        image = cv2.imread(path)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        id = self.ids[index]\n",
    "        image = self._load_image(id)\n",
    "        # Load anns data\n",
    "        all_keypoints = []\n",
    "        keypoints = self.coco.loadAnns(self.coco.getAnnIds(id))\n",
    "        for i, element in enumerate(keypoints):\n",
    "            keypoint = element['keypoints']\n",
    "            keypoint = np.array_split(keypoint, len(keypoint)/3)\n",
    "            height, width = image.shape[:2]\n",
    "            width_scale_factor = 640 / width\n",
    "            height_scale_factor = 480 / height\n",
    "            for point in keypoint:\n",
    "                point[0] = point[0] * width_scale_factor\n",
    "                point[1] = point[1] * height_scale_factor\n",
    "            all_keypoints.append(keypoint)\n",
    "        \n",
    "        image = cv2.resize(image, (640, 480))\n",
    "\n",
    "        torch_image = torchvision.transforms.ToTensor()(image)\n",
    "        return torch_image, image, all_keypoints\n",
    "\n",
    "    # returns number of available images\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
